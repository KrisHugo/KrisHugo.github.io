<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="深度学习专业课内容, Program, Writing, Diary">
    <meta name="description" content="Neutral, Indifference, Inertia;">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>深度学习专业课内容 | Blog of KrisHugo</title>
    <link rel="icon" type="image/png" href="/favicon.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">

    <script src="/libs/jquery/jquery.min.js"></script>

<meta name="generator" content="Hexo 5.4.0"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Blog of KrisHugo</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>留言板</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Blog of KrisHugo</div>
        <div class="logo-desc">
            
            Neutral, Indifference, Inertia;
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			留言板
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			友情链接
		</a>
          
        </li>
        
        
    </ul>
</div>


        </div>

        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/20.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">深度学习专业课内容</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        margin: 35px 0 15px 0;
        padding-left: 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        height: calc(100vh - 250px);
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;

        position: absolute;
        right: 23.5vw;
        display: block;
    }

    .toc-fixed .toc-link::before{
        position: fixed!important;/*当toc的位置改为fixed时，.toc-link::before也要改为fixed*/
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #toc-content .is-active-link::before {
        background-color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/python/">
                                <span class="chip bg-color">python</span>
                            </a>
                        
                            <a href="/tags/AI/">
                                <span class="chip bg-color">AI</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/college/" class="post-category">
                                college
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2020-04-26
                </div>
                

                

                

                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">
        <div class="card-content article-card-content">
            <div id="articleContent">
                <h2 id="深度学习专业课内容"><a href="#深度学习专业课内容" class="headerlink" title="深度学习专业课内容"></a>深度学习专业课内容</h2><p>吴恩达深度学习课程：<br>第一课 — 神经网络与深度学习： <a href="https://www.bilibili.com/video/av66314465/" target="_blank" rel="noopener">av66314465</a><br>第二课 — 改善深层神经网络：超参数调试、正则化以及优化：<a href="https://www.bilibili.com/video/av66524657/?spm_id_from=333.788.b_636f6d6d656e74.19" target="_blank" rel="noopener">av66524657</a><br>第三课 — 结构化机器学习项目：<a href="https://www.bilibili.com/video/av66644404/" target="_blank" rel="noopener">av66644404</a><br>第四课 — 卷积神经网络：<a href="https://www.bilibili.com/video/av66646276/" target="_blank" rel="noopener">av66646276</a><br>第五课 — 序列模型：<a href="https://www.bilibili.com/video/av66647398/" target="_blank" rel="noopener">av66647398</a></p>
<h3 id="专业课概述"><a href="#专业课概述" class="headerlink" title="专业课概述"></a>专业课概述</h3><p>AlphaGo使用的机器学习内容：蒙特卡洛树搜索，两个深度神经网络</p>
<ul>
<li>神经网络内容：<ul>
<li>卷积神经网络：ImageNet（残差网络），Inception<ul>
<li>实际应用：目标检测，人脸验证，图片风格转换</li>
</ul>
</li>
<li>序列模型：网络结构，GRU，LSTM<ul>
<li>实际应用：词嵌入，语言模型，注意力机制，触发语检测</li>
</ul>
</li>
</ul>
</li>
<li>神经网络使用领域：<ul>
<li>计算机视觉<ul>
<li>实际运用<ul>
<li>图像分类</li>
<li>语义分割</li>
<li>物体识别和检测</li>
<li>运动和跟踪</li>
<li>视觉问答</li>
<li>三维重建</li>
</ul>
</li>
</ul>
</li>
<li>自然语言处理<ul>
<li>主要是由两个内容组成<ul>
<li>自然语言理解</li>
<li>自然语言生成</li>
</ul>
</li>
<li>实际运用<ul>
<li>语音识别</li>
<li>机器翻译</li>
<li>语音合成</li>
<li>人机对话</li>
<li>语音助手</li>
<li>问答系统</li>
<li>机器阅读</li>
</ul>
</li>
</ul>
</li>
<li>生成对抗网络<ul>
<li>特质<ul>
<li>通过训练数据进行生成需要的数据</li>
<li>属于监督学习方法</li>
<li>同时训练一个生成网络和一个判别网络<ul>
<li>生成网络：生成逼真的图片欺骗判别网络</li>
<li>判别网络：区分生成图片和真实图片</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>深度学习框架<ul>
<li><strong>TensorFlow</strong> from Google for Industry<ul>
<li>19.10 -&gt; Version 2.0</li>
<li>专业课主要学习的框架，学习版本为1.x，2.0版本与1.x版本差别很大，需要分开学习<ul>
<li>编程语言：python 3.x</li>
<li>编程环境：Anaconda, Jupyter Notebook, TensorFlow 1.x</li>
</ul>
</li>
</ul>
</li>
<li><em>Keras into TensorFlow</em></li>
<li><strong>Pytorch</strong> use Python from Facebook for study</li>
<li>PaddlePaddle from Baidu</li>
<li>Deeplearning4j use JAVA </li>
<li>Mxnet from Amazon</li>
<li><em>Caffe&amp;Caffe2 into Pytorch</em></li>
<li>CNTK from Microsoft</li>
<li>Theano is ancient</li>
<li>Chainer use Python</li>
</ul>
</li>
<li><a href="https://www.bilibili.com/video/BV164411m79z?from=search&seid=16677849041663475348" target="_blank" rel="noopener">学习辅用网上视频课：吴恩达深度学习课程</a></li>
</ul>
<h2 id="第一课：视频课1-6-导论"><a href="#第一课：视频课1-6-导论" class="headerlink" title="第一课：视频课1-6 导论"></a>第一课：视频课1-6 导论</h2><ol>
<li><p>学习顺序</p>
<ol>
<li>(周1-4)Neural Networks and Deep Learning<ul>
<li>Cats Recognition</li>
</ul>
</li>
<li>Improving Deep Neural Network: Hyperparameter tuning(参数调整) , Regularization(正则化) and Optimization(优化)</li>
<li>Structing(结构化) your Machine Learning project. </li>
<li>Convolutional Neural Networks 卷积神经网络</li>
<li>Natural Language Processing.</li>
</ol>
</li>
<li><p>What is a neural network?</p>
<p><em>A function to estimate a result which need a lot of data of parameter to confirm how is the final result decided.</em></p>
<p><strong>We do not setting the method detail of solving problem</strong></p>
</li>
<li><p>Supervised Learning 监管学习</p>
<p>Give a series of Input and Gain a series of Output.</p>
<ul>
<li><p>Example:</p>
<p>​    Home features -&gt; Price (Standard NN)</p>
<p>​    Ad, user Info … -&gt; Click on ad? (Standard NN)</p>
<p>​    Image -&gt; Objects (CNN)</p>
<p>​    Audio -&gt; Text transcript (RNN【Recurrent Neural Network】)</p>
<p>​    English -&gt; Chinese (RNN)</p>
<p>​    Image, Radar Info -&gt; Position of other cars. (Custom / Hybrid)</p>
</li>
</ul>
<p><strong>Standard NN 标准神经网络，Convolutional NN 卷积神经网络，Recurrent NN 循环神经网络</strong></p>
<p><em>Neural Network Make Computer more easy to understand unstructured data.</em></p>
</li>
<li><p>Why are they just now taking off?</p>
<p>scale of data and computation is growing rapidly, and the progress in algorithms.</p>
<p><em>Using a new way (ReLu function instead of Sigmoid function) to faster the speed of training a model.</em></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/ReLu%E5%87%BD%E6%95%B0.png" alt="ReLu函数"></p>
</li>
</ol>
<h2 id="第一课：视频课7-24"><a href="#第一课：视频课7-24" class="headerlink" title="第一课：视频课7-24"></a>第一课：视频课7-24</h2><ol start="7">
<li>Binary Classification<ul>
<li><strong>A great algorithm to process the entire train sets with a great speed.</strong></li>
<li>A introduction of <strong>forward pass or forward propagation step</strong> and <strong>backward pass or backward propagation step</strong> 前向传播和反向传播</li>
<li>Logistic regression 逻辑回归<ul>
<li>An algorithm for binary classification.</li>
</ul>
</li>
<li>Important Notation <ul>
<li>‘n’ is the length of height of the matric X, ‘m’ is the count of training examples (or looks like { (x1, y1) … (x(m), y(m) ) } ). </li>
<li>there are two sets, one of them for train, another for test.</li>
<li>(Xn, Y) is a specific vector.</li>
</ul>
</li>
</ul>
</li>
<li>Logistic Regression<ul>
<li>Given x, want y hat or y^.</li>
<li>Parameters: w (matrix), b (real number)</li>
<li>Output: y^ = w^T * x + b (Sigmoid function) = Sigmoid(Z)<ul>
<li>![sigmoid function](./深度学习专业课内容/Sigmoid function.png “sigmoid function”)</li>
<li><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/Sigmoid(Z).png" alt="Sigmoid(Z)"></li>
<li><em>learn about w and b to know how y become a good estimate.</em></li>
<li><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/MatrixOfResult.png" alt="Another academic method of display" title="Another academic method of display which will be not used in this course"></li>
</ul>
</li>
</ul>
</li>
<li>Logistic Regression cost function</li>
</ol>
<p><strong>To train the parameters W and B of the logistic regression model, We need to define a cost function</strong></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/yHat.png" alt="yHat"></p>
<p>To get the best prediction, we want the y Hat can be more and more near to the i-th example.</p>
<p><strong>Lost funcion</strong> is used to measure how well our algorithm is doing.</p>
<p>Here is the not good algorithm: (which will get serveral global optimums.)</p>
<p>![Old Loss function](./深度学习专业课内容/Old Loss function.png “Old Loss function”)</p>
<p>Here is the better algorithm: (of which graph is convex)</p>
<p>![New Loss function](./深度学习专业课内容/Loss function.png “New Loss Function”)</p>
<p><strong>Cost function:</strong> the cost of the parameters.</p>
<p>![Cost function](./深度学习专业课内容/Cost function.png “Cost function”)</p>
<p>Compute the total cost of the whole sets, Measure how well the performance of your trained model.</p>
<ol start="10">
<li>Gradient Descent 梯度下降法</li>
</ol>
<p><strong>The method to train the w and b.</strong></p>
<p><em>ways: Find the minimum or to say the global optimum.</em></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/GradientDescent.png" alt="Cost Function"></p>
<p>The real usage of Gradient Descent.</p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/GradientDescentAlgorithm.png" alt="GradientDescent"></p>
<p>Parameters in this function:    </p>
<p>​    α ：learning rate ：which to control how big a step we take on each iteration or gradient descent.</p>
<p>​    <strong>w := means updated w equal to the right</strong> </p>
<p><strong>The Key of function</strong></p>
<ul>
<li><strong>using derivatives导数 to find the side which is more near to the optimum</strong></li>
<li>and update the nearest value and repeat it until you can not fould the next value.</li>
</ul>
<ol start="11">
<li>derivatives 导数</li>
</ol>
<p>略（PS:作为一个正在考研的人，要是这里还需要这种入门级的教学，我就别考了hhh）</p>
<ol start="13">
<li>Computation Graph 计算图</li>
</ol>
<p><strong>Also the introduction about derivaives, but the graph makes the procedure of whole computation a lot easier to be comprehended.</strong></p>
<p><em>Example:</em></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/ComputationGraph.png" alt="ComputationGraph"></p>
<p><em>The Compute of Derivatives in Computation Graph</em></p>
<p>![image-20200430115619173](./深度学习专业课内容/The backward propagation.png)</p>
<ol start="15">
<li>Logistic Regression - Gradient descent 逻辑回归中的梯度下降法</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/G:%5CBlog%5CKrisHugo.github.io%5Csource_posts%5C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9%5CLogisticRegressionRecap.png" alt="LogisticRegressionRecap"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/LogisticRegressionDerivatives.png" alt="LogisticRegressionDerivatives"></p>
<p>And Find the derivatives for L : </p>
<p><strong>da = dL / da = - y / a + (1 - y) / (1 - a)</strong></p>
<p><strong>dz = dL / dz =  dL / da * da / dz = dL / da * a(1-a) = a - y</strong></p>
<p>*<em>dw1 = dL / dw1 = x1 * dz = x1 * (a - y) *</em></p>
<p>*<em>dw2 = x2 * dz *</em></p>
<p><strong>db = dz</strong></p>
<h4 id="using-Gradient-descent-on-M-samples"><a href="#using-Gradient-descent-on-M-samples" class="headerlink" title="using Gradient descent on M samples"></a>using Gradient descent on M samples</h4><p>The used function is <strong>J(w, b)</strong></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/LogisticRegressionOnMExamples.png" alt="LogisticRegressionOnMExamples"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/CalculateTheLossFunction.png" alt="CalculateTheLossFunction"></p>
<ol start="17">
<li>Vetorization 向量化</li>
</ol>
<p><strong>A great important method to forbid repeatitive and inefficient looping</strong></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/ExampleForVectorizedSpeed.png" alt="ExampleForVectorizedSpeed"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/Numpy.png" alt="A more faster way of calculate a series of great datasets"></p>
<ol start="19">
<li>Vectorizing Logistic Regression 向量化逻辑回归</li>
</ol>
<p><strong>Using Python Module – Numpy to Simplify the Code</strong></p>
<ol start="20">
<li>Vectorizing Logistic Regresion’s Gradient Computation 向量化逻辑回归的梯度计算</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/ImplementingLogisticRegression.png" alt="ImplementingLogisticRegression"></p>
<ol start="21">
<li>Broadcasting in Python</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/Broadingcasting.png" alt="Broadingcasting"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/ExampleForBroadcasting.png" alt="ExampleForBroadcasting"></p>
<h2 id="第一课：视频课25-35"><a href="#第一课：视频课25-35" class="headerlink" title="第一课：视频课25-35"></a>第一课：视频课25-35</h2><ol start="25">
<li><p>Neural Network Overview</p>
</li>
<li><p>Neural Network Representation</p>
</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200515110302243.png" alt="Neural Network Representation"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200515110648704.png" alt="image-20200515110648704"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200515111536381.png" alt="image-20200515111536381"></p>
<ol start="28">
<li>Vertorizing</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200515112005402.png" alt="image-20200515112005402"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200515112240179.png" alt="image-20200515112240179"></p>
<ol start="30">
<li>Activation functions</li>
</ol>
<p>Here are four useful and often activation function:</p>
<ul>
<li>sigmoid : It doesn’t to be used any more, because it has some disadventages</li>
<li>tanh: limit the output between 0 and 1</li>
<li>ReLU: Rectified limit Unit – a = max(0, 1) <strong>(Mr.Wu recommend)</strong></li>
<li>Leaky ReLU: Rectified limit Unit which is not zero when input go down zero.</li>
</ul>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200515114039515.png" alt="image-20200515114039515"></p>
<ol start="31">
<li>Why we use non-linear activate function.</li>
</ol>
<p>If we use linear activate function in neural network, the whole hidden layers is useless, and it may be OK when you wanna computing output a real number.*<em>So we only use linear function in the final output layer, except for some special circumstance. *</em>but In that case, using ReLU is fine, too</p>
<ol start="32">
<li>the deriviatives of Activate functions</li>
</ol>
<ul>
<li>sigmoid -&gt; a’ = sigmoid’(z) =  a (1 - a)</li>
<li>tanh -&gt; a’ = tanh’(z) = 1 - a^2</li>
<li>ReLU -&gt; a’ = (max(0, z))’ = 0, if z &lt; 0; 1, if z &gt;= 0.</li>
<li>Leaky ReLU -&gt; a’ = (max(0.01 * z, z))’ = 0.01, if z &lt; 0; 1 if z &gt;=0.</li>
</ul>
<ol start="33">
<li>Gradient descent for neural networks</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200515120536239.png" alt="image-20200515120536239"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200515121112957.png" alt="backward propagation"></p>
<ol start="35">
<li><p>Randomly Initialization</p>
<p>If we don’t randomly initialize paremeter W, we will get the same result from each unit in one </p>
</li>
</ol>
<p>layer. It will make out gradient descent to doesn’t work by makes the units output the same results.</p>
<p><strong>b initialized by zeros is OK, but W should be randomly initialized.</strong></p>
<p>In Python: </p>
<ul>
<li><p>w1 = np.random.rand((a, b)) * 0.01 (<em>why here is 0.01 instead of 100 or 1000?</em>)</p>
<ul>
<li><strong>the latter multiplier usually be very small because if this parameter become too large, it makes the sigmoid function or tanh or others useless, hence it makes the learning too slow.</strong></li>
</ul>
</li>
<li><p>b1 = np.zero((b, 1))</p>
</li>
</ul>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200518213524372.png" alt="image-20200518213524372"></p>
<h2 id="第一课：视频课36-43"><a href="#第一课：视频课36-43" class="headerlink" title="第一课：视频课36-43"></a>第一课：视频课36-43</h2><ol start="36">
<li>Deep L-layer Neural network</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200522101551302.png" alt="image-20200522101551302"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200522101958747.png" alt="image-20200522101958747"></p>
<ol start="38">
<li>getting your matrix dimensions right</li>
</ol>
<p>单变量的情况下：</p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200522104705786.png" alt="image-20200522104705786"></p>
<p>Z[l] -&gt; (n[l], 1); A[I] -&gt;  (n[l], 1);</p>
<p>向量化后：<strong>when function plus parameter b, python will automatically using broadcast to duplicate b into a (n, m) matrix</strong></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200522105131223.png" alt="image-20200522105131223"></p>
<ol start="39">
<li>Why deep representations?</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200522110207245.png" alt="image-20200522110207245"></p>
<ol start="40">
<li>Building blocks of deep neural networks</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200522111438793.png" alt="image-20200522111438793"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200522111720050.png" alt="image-20200522111720050"></p>
<ol start="37">
<li>Forward propagation in a deep network</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200522102625960.png" alt="image-20200522102625960"></p>
<ol start="41">
<li>Forward and backward propagation</li>
</ol>
<p><strong>Forward propagation:</strong></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200522112104484.png" alt="image-20200522112104484"></p>
<p><strong>Backward propagation:</strong></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200522112407294.png" alt="image-20200522112407294"></p>
<p><strong>Noticing the backward propagation initialization parameter ==dA==</strong></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200522112701454.png" alt="image-20200522112701454"></p>
<ol start="42">
<li>Parameters ==vs== Hyperparameters</li>
</ol>
<p>Hyperparameters is controlled by researchers, which could directly effect the paramters ==W, B==;</p>
<h2 id="第二课：视频课1-14"><a href="#第二课：视频课1-14" class="headerlink" title="第二课：视频课1-14"></a>第二课：视频课1-14</h2><ol>
<li>Train / dev / test sets</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200525092506646.png" alt="image-20200525092506646"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200525093136620.png" alt="image-20200525093136620"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200525093421911.png" alt="image-20200525093421911"></p>
<ol start="2">
<li>Bias / Variance 偏差/方差</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200525093718667.png" alt="image-20200525093718667"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200525094113692.png" alt="image-20200525094113692"></p>
<ol start="3">
<li>Basic recipe for machine learning</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200525095149437.png" alt="image-20200525095149437"></p>
<ol start="4">
<li>Regularization 正则化</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200525095646075.png" alt="image-20200525095646075"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200525100202996.png" alt="image-20200525100202996"></p>
<ol start="5">
<li>Why regularization reduces overfittings?</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200525101523571.png" alt="image-20200525101523571"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200525101056476.png" alt="image-20200525101056476"></p>
<ol start="6">
<li>Dropout regularization 随机失活正则化</li>
</ol>
<p>Randomly choose several units in each layer and set them disabled</p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200525102156007.png" alt="image-20200525102156007"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200525103248930.png" alt="image-20200525103248930"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200525103527601.png" alt="image-20200525103527601"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200525104132554.png" alt="image-20200525104132554"></p>
<ol start="8">
<li>Other regularization methods</li>
</ol>
<p>Data augmentation (when we can’t get more data)</p>
<p>flipping horizontally, rotated or distortion</p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200525105156574.png" alt="image-20200525105156574"></p>
<p>Early stopping (avoid overfitting)</p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200525105734977.png" alt="image-20200525105734977"></p>
<ol start="9">
<li>Normalizing inputs</li>
</ol>
<p>There are two steps:</p>
<ul>
<li>subtract mean (zero mean)</li>
<li>normalize variance </li>
</ul>
<p><strong>Use the same mu and sigma in train set and test set</strong></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200525110214245.png" alt="image-20200525110214245"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200525110622485.png" alt="image-20200525110622485"></p>
<ol start="10">
<li>Vanishing / exploding gradients</li>
</ol>
<p>If each W greater than 1, the activation will be exploding.</p>
<p>If each W smaller than 1, the activation will be vanishing.</p>
<p>They will also make the learning very slow.</p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200525111309317.png" alt="image-20200525111309317"></p>
<ol start="11">
<li>Weight initialization for deep network</li>
</ol>
<p>Because of the existence of Vanishing / exploding gradients, we have to take careful in weight initialization.</p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200525112033756.png" alt="image-20200525112033756"></p>
<ol start="12">
<li>Gradient checking</li>
</ol>
<p><strong>For checking if the compute of derivatives is correct.</strong></p>
<p> Numerical approximation of gradients 梯度数值逼近</p>
<p>Using the double sides derivative, which makes the Error much less than one side derivative.</p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200525113200276.png" alt="image-20200525113200276"></p>
<p>Gradient checking</p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200525113515862.png" alt="image-20200525113515862"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200525113823819.png" alt="image-20200525113823819"></p>
<ol start="14">
<li>Gradient Checking implementation notes.</li>
</ol>
<ul>
<li>Don’t use in training, only to debug.</li>
<li>If algorithm fails grad check, look at components to try to identify bug.</li>
<li>Remember regularization.</li>
<li>Doesn’t work with dropout.</li>
<li>Run at ramdom initialization; perhaps again after some training.</li>
</ul>
<h2 id="第二课：视频课15-24"><a href="#第二课：视频课15-24" class="headerlink" title="第二课：视频课15-24"></a>第二课：视频课15-24</h2><ol start="15">
<li><p>Mini-batch gradent descent</p>
<p>When <strong>the count of sample</strong> is too large, the speed of using your algorithm will still be too slow to compute. </p>
</li>
</ol>
<p>Mini-batch means a little sets of trainning samples extracted from a whole tremendous training samples sets.</p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200530164024668.png" alt="image-20200530164024668"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200530164538205.png" alt="image-20200530164538205"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200530164819579.png" alt="image-20200530164819579"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200530171013466.png" alt="image-20200530171013466"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200530171241167.png" alt="image-20200530171241167"></p>
<ol start="17">
<li>Exponentially weighted averages. 指数加权平衡</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200530204422817.png" alt="image-20200530204422817"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200531095044302.png" alt="image-20200531095044302"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200531095701942.png" alt="image-20200531095701942"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200531095919807.png" alt="image-20200531095919807"></p>
<p>The adventages of exponentially weighted averages:</p>
<ul>
<li>it just takes up one line of code basically. 只占用一行代码 </li>
<li>and just storage and memory for a single row number to compute this exponentially weighted average. 只需要存储单行数字内容</li>
<li>not the best and most accurate way to compute average.</li>
</ul>
<ol start="19">
<li>Bias correction in exponentially weighted averages</li>
</ol>
<p>In last example, using exponentially weighted averages might make the first several averages too low to be accurate to portray the first several days temperature.</p>
<p>So, we have to use bias to fix it.</p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200531100714813.png" alt="image-20200531100714813"></p>
<p>The bias will go very near to zero when days go up, so we don’t worry about the influence of bias in rear samples.</p>
<p><strong>Most people don’t care about it unless you have to concentrate on the first several indics</strong></p>
<ol start="20">
<li>Gradient descent with momentum 动量梯度下降法</li>
</ol>
<p>In previous methods, we have to make the learning rate low lest make the predictions go far away from the minimum.  </p>
<p>In Gradient descent with momentum, we using the exponentially weighted averages as our forward momentum to keep the learning orientation is point to the position of the minimum.</p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200531101841756.png" alt="image-20200531101841756"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200531102131122.png" alt="image-20200531102131122"></p>
<ol start="21">
<li>RMSprop </li>
</ol>
<p>Another way to speed up gradient descent.</p>
<p><em>I do not really comprehend understand it.</em></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200531103133043.png" alt="image-20200531103133043"></p>
<ol start="22">
<li>Adam optimization algorithm</li>
</ol>
<p>Adam : Adaption Moment Estimation</p>
<p>Another way to speed up gradient descent using in generally</p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200531105317686.png" alt="image-20200531105317686"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200531105418927.png" alt="image-20200531105418927"></p>
<ol start="23">
<li>Learning rate decay</li>
</ol>
<p>There are several way to make the learning rate goes down with the iteration goes through.</p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200531105938019.png" alt="image-20200531105938019"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200531110051578.png" alt="image-20200531110051578"></p>
<ol start="24">
<li>The problem of local optima 局部最优问题</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200531110604893.png" alt="image-20200531110604893"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200531110724616.png" alt="image-20200531110724616"></p>
<p><strong>The optimization methods could help us exemplify from the local optima</strong></p>
<h2 id="第二课：视频课25-35"><a href="#第二课：视频课25-35" class="headerlink" title="第二课：视频课25-35"></a>第二课：视频课25-35</h2><ol start="25">
<li>Tuning process 调试处理</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200601204302879.png" alt="image-20200601204302879"></p>
<p>Find the best hyperparameters‘ values</p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200601204634913.png" alt="image-20200601204634913"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200601204808739.png" alt="image-20200601204808739"></p>
<ol start="26">
<li>Using an appropriate scale to pick hyperparameters</li>
</ol>
<p>A normal way to choose but not for all.</p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200601205022283.png" alt="image-20200601205022283"></p>
<p>A special way for estimate the hyperparameters which is sensitive for a very small changes. <img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200601205248898.png" alt="image-20200601205248898"></p>
<p>Because of the trait of exponentially weighted averages, which is when it comes too close to 1,  the influence of it will become more and more intensive. </p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200601205745768.png" alt="image-20200601205745768"></p>
<ol start="27">
<li>Hyperparameters tuning in practice: Pandas vs. Caviar</li>
</ol>
<p>The two different way of hyperparameters tuning.</p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200601210803581.png" alt="image-20200601210803581"></p>
<ol start="28">
<li>Normalizing activations in a network.</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200601211313319.png" alt="image-20200601211313319"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200601211758052.png" alt="image-20200601211758052"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200601214817911.png" alt="image-20200601214817911"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200601215137626.png" alt="image-20200601215137626"></p>
<ol start="30">
<li>Why Batch Norm work?</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200603111555383.png" alt="image-20200603111555383"></p>
<p>the function of Batch Norm is to control the mean (to zero) and variance (to one) of the input of each hidden layers by transfer the shape of input to normal distribution.</p>
<p>so why we have to control the mean and variance?</p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200603112741076.png" alt="image-20200603112741076"></p>
<p>this controlling is to undermine covariate shift which means the precede hidden layers’ parameters updated could put a great influence into the output, affect the latter hidden layers’ parameters, which means in chinese “牵一发而动全身”. It makes the updating of neural networks is unstable and chaos, which I mean when our newest data have a great difference from prior data, the neural network might perform worse.</p>
<p>but using inputs with the shape of normal distribution could avert it.</p>
<p><strong>So the truly meaning of using batch norm is to make each hidden layer more independent.</strong></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200603113317734.png" alt="image-20200603113317734"></p>
<ol start="31">
<li>Batch norm at test time</li>
</ol>
<p>In test time, we need other way to calculate mu and sigma</p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200603114739137.png" alt="image-20200603114739137"></p>
<ol start="32">
<li>Softmax regression</li>
</ol>
<p>one of generalizations of logical regression</p>
<p>Not just binary classification, but could give a variety of result.</p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200603115657782.png" alt="image-20200603115657782"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200603120159683.png" alt="image-20200603120159683"></p>
<p><strong>The different is input a vector, output a vector</strong></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200603120441817.png" alt="image-20200603120441817"></p>
<ol start="33">
<li>Training a softmax classification.</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200603120759334.png" alt="image-20200603120759334"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200603121403079.png" alt="image-20200603121403079"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200603121622370.png" alt="image-20200603121622370"></p>
<ol start="34">
<li>Deep Learning frameworks</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200603121814542.png" alt="image-20200603121814542"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200603121851611.png" alt="image-20200603121851611"></p>
<ol start="35">
<li>TensorFlow</li>
</ol>
<ul>
<li>Basically using</li>
</ul>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200603122748753.png" alt="image-20200603122748753"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200603122903528.png" alt="image-20200603122903528"></p>
<ul>
<li>input data</li>
</ul>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200603123148606.png" alt="image-20200603123148606"></p>
<ul>
<li>whole code example</li>
</ul>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200603123435243.png" alt="image-20200603123435243"></p>
<h2 id="第三课：视频课1-12"><a href="#第三课：视频课1-12" class="headerlink" title="第三课：视频课1-12"></a>第三课：视频课1-12</h2><ol>
<li>Why is ML strategy</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200606091453068.png" alt="image-20200606091453068"></p>
<p>How to choose the best method for improve the performance of ML.</p>
<ol start="2">
<li>Orthogonalization 正交化</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200606092046899.png" alt="image-20200606092046899"></p>
<p>Orthogonalization means let each parameter when it changes will not affect other parameters.</p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200606092742211.png" alt="image-20200606092742211"></p>
<ol start="3">
<li>Single number evaluation metric 单一数字评估指标</li>
</ol>
<p>Precision 查准率 of the example that your classifier recognizes as cats, what percentage actually are cats?</p>
<p>Recall 查全率 of all the images that really are cats, what percentage were correctly recognized by your classifier?</p>
<p>F1 Score  <strong>the mixture of P and R</strong></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200606102433184.png" alt="image-20200606102433184"></p>
<p>By using the average, it make us easy to figure out which classifier is performing better than others classifier overall.</p>
<ol start="4">
<li>Satisficing and optimizing metrics.</li>
</ol>
<p>We should care about both accuracy and running time.</p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200606103351231.png" alt="image-20200606103351231"></p>
<ol start="5">
<li>Train/dev/test distributions</li>
</ol>
<p><strong>One bad idea: using not really randomly choosed sets for equally distributing.</strong></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200610103534117.png" alt="image-20200610103534117"></p>
<p>==A real great idea is to set the dev and test sets both have data containing all apperent conditions such as region in this example.==</p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200610103903800.png" alt="image-20200610103903800"></p>
<ol start="6">
<li>Size of dev and test sets</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200610104151103.png" alt="image-20200610104151103"></p>
<p><strong>But in the era of big data, we have to change ways to decide the size of dev and test sets</strong></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200610104248502.png" alt="image-20200610104248502"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200610104500075.png" alt="image-20200610104500075"></p>
<ol start="7">
<li>When to change dev/test sets and metrics</li>
</ol>
<p><strong>Sometimes, one algorithm maybe perform greater than others, but it will output some unacceptible results when it goes wrong. So we may not use it because of terrible consequence because of the algorithm’s low-possible but inexorable blunder.</strong></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200610105102600.png" alt="image-20200610105102600"></p>
<p><strong>Here are our usage which weighting the index of each error emerging to make us get the best algorithm which fits our individually special demand</strong></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200610110225404.png" alt="image-20200610110225404"></p>
<ol start="8">
<li>Why human-level perormance</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200610110759027.png" alt="image-20200610110759027"></p>
<p>Bayes optimal error, or Bayesian optimal error, or Bayes error for short is the very best theoretical function for mapping from x to y. </p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200610111146468.png" alt="image-20200610111146468"></p>
<ol start="9">
<li>Avoidable bias</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200611115346592.png" alt="image-20200611115346592"></p>
<ol start="10">
<li>Understanding human-level performance</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200613091305773.png" alt="image-20200613091305773"></p>
<p><strong>How should you define human-level error?</strong></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200613092311029.png" alt="image-20200613092311029"></p>
<p>*<em>Of course we should use the best performance as human-level error, to substitute or estimate the Bayes error, but it this case, when our AI do not perform good enough, choose using anyone to be Bayes error is meaningless. *</em></p>
<p><strong>When avoidable bias is non-ignorable, we should keep eyes on  Bias, otherwise we should pay attention to Variance.</strong></p>
<ol start="11">
<li>Surpassing human-level performance</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200613093244367.png" alt="image-20200613093244367"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200613093611006.png" alt="image-20200613093611006"></p>
<ol start="12">
<li>Improving your model performance</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200613094016023.png" alt="image-20200613094016023"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200613094305142.png" alt="image-20200613094305142"></p>
<h2 id="第三课：视频课13-22"><a href="#第三课：视频课13-22" class="headerlink" title="第三课：视频课13-22"></a>第三课：视频课13-22</h2><ol start="13">
<li>Carring out error analysis 错误分析</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200615144412091.png" alt="image-20200615144412091"></p>
<ol>
<li>Found how the error may be caused.</li>
<li>Figure out the possible reasons.</li>
<li>Use a sheet to statistic.</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200615145025091.png" alt="image-20200615145025091"></p>
<ol start="14">
<li>cleaning up incorrectly labeled data</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200615145422040.png" alt="image-20200615145422040"></p>
<p>So long as the total data set is big enough, the random error is ok, but the systematic errors is not ok.</p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200615150053960.png" alt="image-20200615150053960"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200615150516455.png" alt="image-20200615150516455"></p>
<ol start="15">
<li>Build your first system quickly, then iterate</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200615151036893.png" alt="image-20200615151036893"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200615151140380.png" alt="image-20200615151140380"></p>
<p><strong>Guideline: Build a system first, and iterate.</strong></p>
<ol start="16">
<li>Training and testing on different distributions.</li>
</ol>
<p>There are two ways to solve it.</p>
<ol>
<li>Merge them and shuffle.</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200615153559584.png" alt="image-20200615153559584"></p>
<ol start="2">
<li>use basis dataset to train, and the real worthy data to test.</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200615154153186.png" alt="image-20200615154153186"></p>
<ol start="17">
<li>Bias and Variance with mismatched data distributions</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200615160321279.png" alt="image-20200615160321279"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200615160644471.png" alt="image-20200615160644471"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200615161232388.png" alt="image-20200615161232388"></p>
<ol start="18">
<li>Addressing data mismatch</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200615161755207.png" alt="image-20200615161755207"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200615161946845.png" alt="image-20200615161946845"></p>
<ol start="19">
<li>Transfer learning 迁移学习</li>
</ol>
<p>Use old knowledge in new task</p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200615163710699.png" alt="image-20200615163710699"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200615164002861.png" alt="image-20200615164002861"></p>
<ol start="20">
<li>Multi-task learning 多任务学习</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200615164203212.png" alt="image-20200615164203212"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200615164535439.png" alt="image-20200615164535439"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200615164843129.png" alt="image-20200615164843129"></p>
<ol start="21">
<li>End-to-End deep learning 端对端深度学习</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200615165235342.png" alt="image-20200615165235342"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200615165819492.png" alt="image-20200615165819492"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200615165939240.png" alt="image-20200615165939240"></p>
<ol start="22">
<li>Whether to use end-to-end deep learning</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200615170349079.png" alt="image-20200615170349079"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200615170925241.png" alt="image-20200615170925241"></p>
<h2 id="第四课：视频课1-11"><a href="#第四课：视频课1-11" class="headerlink" title="第四课：视频课1-11"></a>第四课：视频课1-11</h2><ol>
<li>Computer Vision</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200616084951453.png" alt="image-20200616084951453"></p>
<ol start="2">
<li>Edge Detection</li>
</ol>
<p><strong>Convolution 卷积</strong></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200616085511773.png" alt="image-20200616085511773"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200616085604059.png" alt="image-20200616085604059"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200616085655347.png" alt="image-20200616085655347"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200616085806762.png" alt="image-20200616085806762"></p>
<p>The usage of convolution in Vertical edge detection</p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200616090001930.png" alt="image-20200616090001930"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200616090644499.png" alt="image-20200616090644499"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200616090731360.png" alt="image-20200616090731360"></p>
<ol start="4">
<li>Padding</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200616091338859.png" alt="image-20200616091338859"></p>
<p><strong>Two strategy of Padding convolutions</strong></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200616091512938.png" alt="image-20200616091512938"></p>
<p><strong>We usually use odd-numbered f for building filter</strong></p>
<ol start="5">
<li>Strided convolution</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200616091748865.png" alt="image-20200616091748865"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200616091757404.png" alt="image-20200616091757404"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200616091814573.png" alt="image-20200616091814573"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200616091925121.png" alt="image-20200616091925121"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200616092444984.png" alt="image-20200616092444984"></p>
<ol start="6">
<li>Convolution over volumes</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200616092639613.png" alt="image-20200616092639613"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200616092811448.png" alt="image-20200616092811448"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200616093039875.png" alt="image-20200616093039875"></p>
<ol start="7">
<li>One layer of convolutional neural network</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200616093610946.png" alt="image-20200616093610946"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200616093711561.png" alt="image-20200616093711561"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200616094232888.png" alt="image-20200616094232888"></p>
<p><strong>An Example of ConvNet</strong></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200616095041404.png" alt="image-20200616095041404"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200616095216286.png" alt="image-20200616095216286"></p>
<ol start="9">
<li>Pooling layers 池化层（汇合层）</li>
</ol>
<p><strong>Use Pooling layers to reduce the size of their representation to speed up computtion, as wel as to some of the features it detects a bit more rebust. 缩减模型大小，提高计算速度，同时提高所提取特征的健壮性</strong></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200616095619531.png" alt="image-20200616095619531"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200616095802291.png" alt="image-20200616095802291"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200616100019095.png" alt="image-20200616100019095"></p>
<ol start="10">
<li>Neural network example</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200616100952112.png" alt="image-20200616100952112"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200616101006120.png" alt="image-20200616101006120"></p>
<ol start="11">
<li>Why convolution?</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200616101443682.png" alt="image-20200616101443682"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200616101630163.png" alt="image-20200616101630163"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200616101947696.png" alt="image-20200616101947696"></p>
<h3 id="第四课：视频课12-22"><a href="#第四课：视频课12-22" class="headerlink" title="第四课：视频课12-22"></a>第四课：视频课12-22</h3><ol start="12">
<li>Why look at cases studies?</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200622195228815.png" alt="image-20200622195228815"></p>
<ol start="13">
<li>Classic networks</li>
</ol>
<ul>
<li><strong>LeNet - 5 : Recognize the number written by hand</strong></li>
</ul>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200622195928733.png" alt="image-20200622195928733"></p>
<ul>
<li>Alex Net</li>
</ul>
<p>Input a picture, return a series.</p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200622200326093.png" alt="image-20200622200326093"></p>
<ul>
<li>VGG - 16</li>
</ul>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200626102816754.png" alt="image-20200626102816754"></p>
<ol start="14">
<li>Residual Network — Res Net</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200626103551402.png" alt="image-20200626103551402"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200626103751284.png" alt="image-20200626103751284"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200626104551750.png" alt="image-20200626104551750"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200626104906027.png" alt="image-20200626104906027"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200626105033227.png" alt="image-20200626105033227"></p>
<ol start="16">
<li>Network in Network and 1 * 1 convolutions</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200626105530885.png" alt="image-20200626105530885"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200626105656715.png" alt="image-20200626105656715"></p>
<ol start="17">
<li>Inception Network Motivation</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200626110040713.png" alt="image-20200626110040713"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200626110247040.png" alt="image-20200626110247040"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200626110517819.png" alt="image-20200626110517819"></p>
<p>1*1 convolution use to reduce the size of third layers</p>
<ol start="18">
<li>Inception Network</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200626110818596.png" alt="image-20200626110818596"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200626111002896.png" alt="image-20200626111002896"></p>
<ol start="19">
<li>Using open-source implementations</li>
</ol>
<p>Github</p>
<ol start="20">
<li>Transfer Learning</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200626111551586.png" alt="image-20200626111551586"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200626111711592.png" alt="image-20200626111711592"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200626111812124.png" alt="image-20200626111812124"></p>
<ol start="21">
<li>Data augmentation</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200626112129330.png" alt="image-20200626112129330"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200626112227329.png" alt="image-20200626112227329"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200626112411712.png" alt="image-20200626112411712"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200626112530514.png" alt="image-20200626112530514"></p>
<ol start="22">
<li>The state of computer vision</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200626112849086.png" alt="image-20200626112849086"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200626113335320.png" alt="image-20200626113335320"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200626113601239.png" alt="image-20200626113601239"></p>
<h3 id="第四课-视频课22-32"><a href="#第四课-视频课22-32" class="headerlink" title="第四课 视频课22-32"></a>第四课 视频课22-32</h3><ol start="22">
<li>Object localization</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200626130754143.png" alt="image-20200626130754143"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200626131613768.png" alt="image-20200626131613768"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200626131924761.png" alt="image-20200626131924761"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200626132129076.png" alt="image-20200626132129076"></p>
<ol start="23">
<li>Landmark detection</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200626133150844.png" alt="image-20200626133150844"></p>
<ol start="24">
<li>Object detection</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200626134703112.png" alt="image-20200626134703112"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200626134920442.png" alt="image-20200626134920442"></p>
<ol start="25">
<li>Convolutional implementation of sliding windows</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200626135530490.png" alt="image-20200626135530490"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200626141058696.png" alt="image-20200626141058696"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200626141205599.png" alt="image-20200626141205599"></p>
<ol start="27">
<li>Bouding box prediction</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200626141323362.png" alt="image-20200626141323362"></p>
<p><strong>YOLO algorithm</strong></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200626170208739.png" alt="image-20200626170208739"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200626170233582.png" alt="image-20200626170233582"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200626170446787.png" alt="image-20200626170446787"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200626171014053.png" alt="image-20200626171014053"></p>
<ol start="28">
<li>Intersection over union 交并比</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200626171327450.png" alt="image-20200626171327450"></p>
<p><strong>Is it good enough or too bad?</strong></p>
<p>We have to use a algorithm to evaluate it.</p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200626171519270.png" alt="image-20200626171519270"></p>
<ol start="29">
<li>Non-max suppresion 非极大值抑制</li>
</ol>
<p>One result only be detected once.</p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200626172514450.png" alt="image-20200626172514450"></p>
<ol start="30">
<li>Anchor Boxes</li>
</ol>
<p>Detect multiple objects.</p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200626173155401.png" alt="image-20200626173155401"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200626173254454.png" alt="image-20200626173254454">)<img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200626173556907.png" alt="image-20200626173556907"></p>
<ol start="31">
<li>YOLO algorithm</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200626174008319.png" alt="image-20200626174008319"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200626174316780.png" alt="image-20200626174316780"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200626174513394.png" alt="image-20200626174513394"></p>
<ol start="32">
<li>Region proposals 候选区域</li>
</ol>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200626175039025.png" alt="image-20200626175039025"></p>
<p><img src="/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/image-20200626180816656.png" alt="image-20200626180816656"></p>
<h3 id="第四课：视频课33-43"><a href="#第四课：视频课33-43" class="headerlink" title="第四课：视频课33-43"></a>第四课：视频课33-43</h3>
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="http://example.com" rel="external nofollow noreferrer">Kris Hugo</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="http://example.com/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/">http://example.com/2020/04/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%93%E4%B8%9A%E8%AF%BE%E5%86%85%E5%AE%B9/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="http://example.com" target="_blank">Kris Hugo</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/python/">
                                    <span class="chip bg-color">python</span>
                                </a>
                            
                                <a href="/tags/AI/">
                                    <span class="chip bg-color">AI</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2020/04/28/%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98%E5%90%88%E9%9B%86/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/15.jpg" class="responsive-img" alt="服务器遇到的问题合集">
                        
                        <span class="card-title">服务器遇到的问题合集</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            服务器遇到的问题合集
如果需要查找docker容器中的es的elasticsearch.yml配置文件进行错误修正的话，由于容器文件夹过于复杂，需要进行文件查找
解决办法：
123find / -name elasticsearch.yml
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2020-04-28
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/linux/" class="post-category">
                                    linux
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/%E9%97%AE%E9%A2%98/">
                        <span class="chip bg-color">问题</span>
                    </a>
                    
                    <a href="/tags/linux/">
                        <span class="chip bg-color">linux</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2020/04/26/Python-%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E5%BA%94%E7%94%A8/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/14.jpg" class="responsive-img" alt="Python 数据分析与应用">
                        
                        <span class="card-title">Python 数据分析与应用</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Python 数据分析与应用基本语法
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2020-04-26
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/college/" class="post-category">
                                    college
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/python/">
                        <span class="chip bg-color">python</span>
                    </a>
                    
                    <a href="/tags/big-data/">
                        <span class="chip bg-color">big data</span>
                    </a>
                    
                    <a href="/tags/data-analyze/">
                        <span class="chip bg-color">data analyze</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>


<script>
    $('#articleContent').on('copy', function (e) {
        // IE8 or earlier browser is 'undefined'
        if (typeof window.getSelection === 'undefined') return;

        var selection = window.getSelection();
        // if the selection is short let's not annoy our users.
        if (('' + selection).length < Number.parseInt('120')) {
            return;
        }

        // create a div outside of the visible area and fill it with the selected text.
        var bodyElement = document.getElementsByTagName('body')[0];
        var newdiv = document.createElement('div');
        newdiv.style.position = 'absolute';
        newdiv.style.left = '-99999px';
        bodyElement.appendChild(newdiv);
        newdiv.appendChild(selection.getRangeAt(0).cloneContents());

        // we need a <pre> tag workaround.
        // otherwise the text inside "pre" loses all the line breaks!
        if (selection.getRangeAt(0).commonAncestorContainer.nodeName === 'PRE') {
            newdiv.innerHTML = "<pre>" + newdiv.innerHTML + "</pre>";
        }

        var url = document.location.href;
        newdiv.innerHTML += '<br />'
            + '来源: Blog of KrisHugo<br />'
            + '文章作者: Kris Hugo<br />'
            + '文章链接: <a href="' + url + '">' + url + '</a><br />'
            + '本文章著作权归作者所有，任何形式的转载都请注明出处。';

        selection.selectAllChildren(newdiv);
        window.setTimeout(function () {bodyElement.removeChild(newdiv);}, 200);
    });
</script>


<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>


<!-- 代码块折行 -->

<style type="text/css">
code[class*="language-"], pre[class*="language-"] { white-space: pre !important; }
</style>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/libs/aplayer/APlayer.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script>

    
    <div class="container row center-align" style="margin-bottom: 0px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            <span id="year">2019</span>
            <a href="http://example.com" target="_blank">Kris Hugo</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
            
            
            
            
            
            <span id="busuanzi_container_site_pv">
                |&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv"
                    class="white-color"></span>&nbsp;次
            </span>
            
            
            <span id="busuanzi_container_site_uv">
                |&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv"
                    class="white-color"></span>&nbsp;人
            </span>
            
            <br>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/krishugo" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:KrisHugo@163.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=2676086616" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 2676086616" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>





    <a href="https://www.zhihu.com/people/KrisHugo" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/KrisHugo" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



    <a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50">
        <i class="fas fa-rss"></i>
    </a>

</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script src="/js/search.js"></script>
<script type="text/javascript">
$(function () {
    searchFunc("/search.xml", 'searchInput', 'searchResult');
});
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    

    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
